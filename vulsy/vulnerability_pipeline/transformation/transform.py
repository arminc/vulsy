"""Transformation process.

This process receives events from ingestion, we get them from the database but the idea behind is
we are reading a queue, we are not transforming the data directly.
Instead, it records the necessary steps for transformation.
A separate process is responsible for the actual transformation,
enabling us to maintain a clear record of which events have been transformed and which have not.

This approach facilitates retries and allows for the transformation of the same event multiple times if necessary.
While it is possible to store the ingestion event data again at this stage, we avoid data duplication here
as we are using the same database (data source) for both ingestion and transformation in this implementation.
"""

import logging
import time
from abc import ABC, abstractmethod
from datetime import datetime

from vulsy.common.simpel import now
from vulsy.vulnerability_pipeline.ingestion.models import EndpointRawDataEvent
from vulsy.vulnerability_pipeline.transformation.models import (
    EndpointEventMetadata,
    EndpointMetadata,
    TransformationError,
    TransformationMetadata,
    TransformationStatus,
)

logger = logging.getLogger(__name__)


class TransformationDataRepository(ABC):
    """Interface for the transformation data repository."""

    @abstractmethod
    def get_next_ingestion_event(self, last_timestamp: str) -> tuple[str, EndpointRawDataEvent] | None:
        """Retrieve next ingestion event that need to be transformed.

        We are assuming the events will never have the same timestamp.

        Args:
            last_timestamp: The timestamp to start from.

        Returns:
            Next event and its key or None if no more events.
        """

    @abstractmethod
    def get_transformation_metadata(self) -> TransformationMetadata:
        """Retrieve the transformation metadata.

        Returns:
            Transformation metadata.
        """

    @abstractmethod
    def store_new_metadata(self, meta: TransformationMetadata, endpoint_meta: EndpointMetadata) -> None:
        """Store the transformation metadata and endpoint metadata.

        Args:
            meta: Transformation metadata.
            endpoint_meta: Endpoint metadata.
        """

    @abstractmethod
    def replace_existing_metadata(self, meta: TransformationMetadata, endpoint_meta: EndpointMetadata) -> None:
        """Replace the existing transformation metadata and endpoint metadata.

        Args:
            meta: Transformation metadata.
            endpoint_meta: Endpoint metadata.
        """

    @abstractmethod
    def find_endpoint_metadata(self, key: str) -> EndpointMetadata | None:
        """Retrieve the endpoint metadata for a specific endpoint.

        Returns:
            Endpoint metadata or None if not found.
        """

    @abstractmethod
    def get_next_endpoint_to_transform(self) -> tuple[str, EndpointMetadata] | None:
        """Retrieve the next endpoint to transform.

        Returns:
            Endpoint metadata and its key or None if not found.
        """


def _prepare_new_endpoint_metadata(
    repo: TransformationDataRepository,
    next_event: EndpointRawDataEvent,
    next_event_key: str,
    transformation_metadata: TransformationMetadata,
) -> None:
    """Prepare the new endpoint metadata.

    Args:
        repo: The transformation data repository.
        next_event: The next event to prepare metadata for.
        next_event_key: The key of the next event.
        transformation_metadata: The transformation metadata.
    """
    date = now()
    endpoint_meta = EndpointMetadata(
        timestamp=date,
        url=next_event.url,
        events=[
            EndpointEventMetadata(
                timestamp=now(),
                status=TransformationStatus.UNPROCESSED,
                event_id=next_event_key,
                original_event_timestamp=next_event.timestamp,
            )
        ],
    )
    logger.info("Storing transformed item meta for %s", next_event.url)
    transformation_metadata.last_queued_timestamp = next_event.timestamp
    repo.store_new_metadata(transformation_metadata, endpoint_meta)


def _prapare_existing_endpoint_metadata(
    repo: TransformationDataRepository,
    endpoint_metadata: EndpointMetadata,
    next_event: EndpointRawDataEvent,
    next_event_key: str,
    transformation_metadata: TransformationMetadata,
) -> None:
    """Prepare the existing endpoint metadata.

    Args:
        repo: The transformation data repository.
        endpoint_metadata: The existing endpoint metadata.
        next_event: The next event to prepare metadata for.
        next_event_key: The key of the next event.
        transformation_metadata: The transformation metadata.
    """
    current_timestamp = now()
    # Check for newer events
    for event in endpoint_metadata.events:
        event_timestamp = datetime.fromisoformat(event.original_event_timestamp)
        next_event_timestamp = datetime.fromisoformat(next_event.timestamp)
        if event_timestamp > next_event_timestamp:
            raise TransformationError(
                "Found newer event (%s) than next event (%s) (%s)",
                event.original_event_timestamp,
                next_event.timestamp,
                next_event_key,
            )

    # Mark existing unfinished events as obsolete
    for event in endpoint_metadata.events:
        if event.status in {
            TransformationStatus.UNPROCESSED,
            TransformationStatus.FAILED,
            TransformationStatus.RETRY,
        }:
            event.status = TransformationStatus.OBSOLETE

    # Add new event
    endpoint_metadata.events.append(
        EndpointEventMetadata(
            timestamp=current_timestamp,
            status=TransformationStatus.UNPROCESSED,
            event_id=next_event_key,
            original_event_timestamp=next_event.timestamp,
        )
    )

    endpoint_metadata.timestamp = current_timestamp
    transformation_metadata.last_queued_timestamp = next_event.timestamp
    repo.replace_existing_metadata(transformation_metadata, endpoint_metadata)


def _prepare_next_ingestion_event(repo: TransformationDataRepository) -> None:
    """Prepare the next ingestion event that needs to be transformed.

    Args:
        repo: The transformation data repository.

    Returns:
        None if no more events.
    """
    transformation_metadata = repo.get_transformation_metadata()
    next_ingestion_event = repo.get_next_ingestion_event(transformation_metadata.last_queued_timestamp)
    if next_ingestion_event is None:
        return

    next_event_key, next_event = next_ingestion_event
    try:
        if not next_event.is_signature_valid():
            raise TransformationError("Someone has tempered with the data, signature is not valid")  # noqa: TRY301
    except Exception as e:
        logger.exception("Error preparing next ingestion event")
        raise TransformationError("Signature could not be verified") from e

    # Find the information about this endpoint
    endpoint_metadata = repo.find_endpoint_metadata(next_event.url_as_hash())
    if endpoint_metadata:
        _prapare_existing_endpoint_metadata(
            repo, endpoint_metadata, next_event, next_event_key, transformation_metadata
        )
    else:
        _prepare_new_endpoint_metadata(repo, next_event, next_event_key, transformation_metadata)


def transform(repo: TransformationDataRepository, sleep_time: int = 10) -> None:
    """Transform the source item events."""
    while True:
        _prepare_next_ingestion_event(repo)
        next_endpoint = repo.get_next_endpoint_to_transform()
        if next_endpoint:
            pass
        else:
            time.sleep(sleep_time)
